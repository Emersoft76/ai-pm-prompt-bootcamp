# ğŸ§ ğŸ”§ Lab AvanÃ§ado: Fine-Tuning de Modelos | Model Fine-Tuning

---

## ğŸ‡§ğŸ‡· Objetivo

Neste lab, vocÃª vai aprender como fazer o fine-tuning (ajuste fino) de um modelo de linguagem usando dados prÃ³prios, para melhorar a performance em tarefas especÃ­ficas.

## ğŸ‡ºğŸ‡¸ Objective

In this lab, youâ€™ll learn how to fine-tune a language model using custom data, enhancing its performance on specific tasks.

---

## ğŸ“¦ Tecnologias / Technologies

- ğŸ¤— Hugging Face Transformers
- Datasets (CSV / JSON)
- Google Colab ou GPU local
- Python

---

## âœ… PrÃ©-requisitos

- Conta gratuita no Hugging Face
- Familiaridade com notebooks Python
- Dataset formatado com colunas: `input` e `output`

---

## ğŸ§ª Exemplo de notebook

ğŸ”— [Fine-tuning no Colab com GPT-2](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)

---

## ğŸ“Œ Etapas principais

1. Preparar os dados
2. Escolher modelo base (ex: `gpt2`, `bertimbau`)
3. Configurar Trainer e Tokenizer
4. Rodar fine-tuning e salvar modelo
5. Avaliar resultados

---

## âš ï¸ ObservaÃ§Ã£o

Evite overfitting. Trabalhe com datasets limpos e utilize validaÃ§Ã£o cruzada.

---
